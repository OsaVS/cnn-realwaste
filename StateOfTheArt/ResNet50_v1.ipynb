{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0ede15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad4e96",
   "metadata": {},
   "source": [
    "## Dataset Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d882fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "KAGGLE ENVIRONMENT - IMPROVED RESNET50 TRAINING\n",
      "======================================================================\n",
      "📁 Data directory: ../realwaste/realwaste-main/RealWaste\n",
      "🎯 Target epochs: 60\n",
      "🔢 Classes: 9\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 9\n",
    "NUM_EPOCHS = 60\n",
    "DATA_DIR = '../realwaste/realwaste-main/RealWaste'  # ✅ Kaggle path\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = [\n",
    "    'Cardboard',\n",
    "    'Food Organics',\n",
    "    'Glass',\n",
    "    'Metal',\n",
    "    'Miscellaneous Trash',\n",
    "    'Paper',\n",
    "    'Plastic',\n",
    "    'Textile Trash',\n",
    "    'Vegetation'\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KAGGLE ENVIRONMENT - IMPROVED RESNET50 TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"📁 Data directory: {DATA_DIR}\")\n",
    "print(f\"🎯 Target epochs: {NUM_EPOCHS}\")\n",
    "print(f\"🔢 Classes: {NUM_CLASSES}\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0133c5cc",
   "metadata": {},
   "source": [
    "## Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd9a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WasteDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading waste material images\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "            class_dir = self.root_dir / class_name\n",
    "            if class_dir.exists():\n",
    "                image_files = sorted(class_dir.glob('*.*'))\n",
    "                for img_path in image_files:\n",
    "                    if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                        self.images.append(str(img_path))\n",
    "                        self.labels.append(class_idx)\n",
    "            else:\n",
    "                print(f\"⚠️ Warning: Directory not found: {class_dir}\")\n",
    "        \n",
    "        print(f\"Loaded {len(self.images)} images from {len(CLASS_NAMES)} classes\")\n",
    "        \n",
    "        if len(self.images) == 0:\n",
    "            raise RuntimeError(f\"No images found in {root_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a4be0",
   "metadata": {},
   "source": [
    "### Mixup Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4c2f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"Applies mixup augmentation to batch\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Compute mixup loss\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab710f",
   "metadata": {},
   "source": [
    "## Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c621b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CALCULATING DATASET STATISTICS\n",
      "======================================================================\n",
      "Loaded 4752 images from 9 classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Mean (R, G, B): [0.5959, 0.6181, 0.6327]\n",
      "Dataset Std (R, G, B): [0.1614, 0.1624, 0.1879]\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean_std(dataset_path, image_size=224, sample_size=1000):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    temp_dataset = WasteDataset(root_dir=dataset_path, transform=transform)\n",
    "    \n",
    "    if sample_size and sample_size < len(temp_dataset):\n",
    "        indices = np.random.choice(len(temp_dataset), sample_size, replace=False)\n",
    "        temp_dataset = Subset(temp_dataset, indices)\n",
    "    \n",
    "    loader = DataLoader(temp_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    \n",
    "    channels_sum = torch.zeros(3)\n",
    "    channels_squared_sum = torch.zeros(3)\n",
    "    num_pixels = 0\n",
    "    \n",
    "    for images, _ in loader:\n",
    "        channels_sum += torch.mean(images, dim=[0, 2, 3]) * images.size(0)\n",
    "        channels_squared_sum += torch.mean(images ** 2, dim=[0, 2, 3]) * images.size(0)\n",
    "        num_pixels += images.size(0)\n",
    "    \n",
    "    mean = channels_sum / num_pixels\n",
    "    std = torch.sqrt(channels_squared_sum / num_pixels - mean ** 2)\n",
    "    \n",
    "    print(f\"Dataset Mean (R, G, B): [{mean[0]:.4f}, {mean[1]:.4f}, {mean[2]:.4f}]\")\n",
    "    print(f\"Dataset Std (R, G, B): [{std[0]:.4f}, {std[1]:.4f}, {std[2]:.4f}]\")\n",
    "    \n",
    "    return mean.tolist(), std.tolist()\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CALCULATING DATASET STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "dataset_mean, dataset_std = calculate_mean_std(DATA_DIR, IMAGE_SIZE, sample_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa9632c",
   "metadata": {},
   "source": [
    "## Enhanced data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "520e92b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING ENHANCED TRANSFORMS\n",
      "======================================================================\n",
      "✅ Enhanced augmentation pipeline created\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CREATING ENHANCED TRANSFORMS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.7, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.05),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=dataset_mean, std=dataset_std),\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(int(IMAGE_SIZE * 1.15)),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=dataset_mean, std=dataset_std)\n",
    "])\n",
    "\n",
    "print(\"✅ Enhanced augmentation pipeline created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31797e29",
   "metadata": {},
   "source": [
    "## Load and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f64d400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING AND SPLITTING DATASET\n",
      "======================================================================\n",
      "Loaded 4752 images from 9 classes\n",
      "Train: 3326 | Val: 713 | Test: 713\n",
      "Loaded 4752 images from 9 classes\n",
      "Loaded 4752 images from 9 classes\n",
      "Loaded 4752 images from 9 classes\n",
      "✅ Data loaders created\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LOADING AND SPLITTING DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "full_dataset = WasteDataset(root_dir=DATA_DIR, transform=None)\n",
    "labels = np.array([full_dataset[i][1] for i in range(len(full_dataset))])\n",
    "\n",
    "# Stratified split\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=(val_ratio + test_ratio), random_state=42)\n",
    "train_idx, temp_idx = next(sss1.split(np.arange(len(labels)), labels))\n",
    "\n",
    "temp_labels = labels[temp_idx]\n",
    "relative_test_size = test_ratio / (val_ratio + test_ratio)\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=relative_test_size, random_state=42)\n",
    "val_idx_rel, test_idx_rel = next(sss2.split(np.arange(len(temp_idx)), temp_labels))\n",
    "\n",
    "val_idx = temp_idx[val_idx_rel]\n",
    "test_idx = temp_idx[test_idx_rel]\n",
    "\n",
    "print(f\"Train: {len(train_idx)} | Val: {len(val_idx)} | Test: {len(test_idx)}\")\n",
    "\n",
    "# Create datasets with transforms\n",
    "train_dataset_full = WasteDataset(root_dir=DATA_DIR, transform=train_transform)\n",
    "val_dataset_full = WasteDataset(root_dir=DATA_DIR, transform=val_test_transform)\n",
    "test_dataset_full = WasteDataset(root_dir=DATA_DIR, transform=val_test_transform)\n",
    "\n",
    "train_dataset = Subset(train_dataset_full, train_idx)\n",
    "val_dataset = Subset(val_dataset_full, val_idx)\n",
    "test_dataset = Subset(test_dataset_full, test_idx)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                         num_workers=2, pin_memory=True, drop_last=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                       num_workers=2, pin_memory=True, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=2, pin_memory=True, drop_last=False)\n",
    "\n",
    "print(\"✅ Data loaders created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ba6c0",
   "metadata": {},
   "source": [
    "## Compute Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6e92d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPUTING CLASS WEIGHTS\n",
      "======================================================================\n",
      "📊 Class weights computed\n",
      "  Cardboard           : 1.144 (count: 323)\n",
      "  Food Organics       : 1.283 (count: 288)\n",
      "  Glass               : 1.257 (count: 294)\n",
      "  Metal               : 0.668 (count: 553)\n",
      "  Miscellaneous Trash : 1.068 (count: 346)\n",
      "  Paper               : 1.056 (count: 350)\n",
      "  Plastic             : 0.573 (count: 645)\n",
      "  Textile Trash       : 1.665 (count: 222)\n",
      "  Vegetation          : 1.212 (count: 305)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPUTING CLASS WEIGHTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "train_labels = labels[train_idx].tolist()\n",
    "class_counts = Counter(train_labels)\n",
    "total_train = len(train_labels)\n",
    "class_weights = torch.tensor(\n",
    "    [total_train / (NUM_CLASSES * class_counts[i]) for i in range(NUM_CLASSES)],\n",
    "    dtype=torch.float32\n",
    ").to(device)\n",
    "\n",
    "print(\"📊 Class weights computed\")\n",
    "for i, (name, weight) in enumerate(zip(CLASS_NAMES, class_weights)):\n",
    "    print(f\"  {name:20s}: {weight:.3f} (count: {class_counts[i]:3d})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4a38e5",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bfaebe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING RESNET50 MODEL\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResNet50 loaded with pretrained ImageNet weights\n",
      "   Final layer: 2048 → 9 classes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CREATING RESNET50 MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model = models.resnet50(weights='IMAGENET1K_V1')  # ✅ Updated for newer PyTorch\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"✅ ResNet50 loaded with pretrained ImageNet weights\")\n",
    "print(f\"   Final layer: {in_features} → {NUM_CLASSES} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf4281",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616fd1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING CONFIGURATION\n",
      "======================================================================\n",
      "✅ Optimizer: AdamW (lr=0.001, weight_decay=1e-4)\n",
      "✅ Scheduler: CosineAnnealingWarmRestarts (T_0=10)\n",
      "✅ Loss: CrossEntropyLoss + Label Smoothing + Class Weights\n",
      "✅ Mixup: Enabled (alpha=0.2)\n",
      "✅ Epochs: 60\n",
      "✅ Early Stopping: patience=12\n",
      "\n",
      "======================================================================\n",
      "STARTING TRAINING - IMPROVED RESNET50\n",
      "Epoch [  1/60] (33.9s) | LR: 0.000976 | Train: 32.22% | Val: 34.78% ✨ BEST!\n",
      "Epoch [  2/60] (33.1s) | LR: 0.000905 | Train: 46.71% | Val: 43.90% ✨ BEST!\n",
      "Epoch [  3/60] (33.3s) | LR: 0.000794 | Train: 52.65% | Val: 60.03% ✨ BEST!\n",
      "Epoch [  4/60] (33.3s) | LR: 0.000655 | Train: 57.65% | Val: 67.46% ✨ BEST!\n",
      "Epoch [  5/60] (33.3s) | LR: 0.000501 | Train: 62.24% | Val: 69.14% ✨ BEST!\n",
      "Epoch [  6/60] (33.2s) | LR: 0.000346 | Train: 64.28% | Val: 69.28% ✨ BEST!\n",
      "Epoch [  7/60] (33.2s) | LR: 0.000207 | Train: 67.90% | Val: 75.18% ✨ BEST!\n",
      "Epoch [  8/60] (33.5s) | LR: 0.000096 | Train: 70.93% | Val: 80.65% ✨ BEST!\n",
      "Epoch [  9/60] (33.5s) | LR: 0.000025 | Train: 76.93% | Val: 82.33% ✨ BEST!\n",
      "Epoch [ 10/60] (33.5s) | LR: 0.001000 | Train: 77.19% | Val: 83.17% ✨ BEST!\n",
      "Epoch [ 11/60] (33.5s) | LR: 0.000976 | Train: 67.65% | Val: 70.97%\n",
      "Epoch [ 12/60] (33.5s) | LR: 0.000905 | Train: 65.25% | Val: 69.99%\n",
      "Epoch [ 13/60] (33.5s) | LR: 0.000794 | Train: 69.23% | Val: 68.02%\n",
      "Epoch [ 14/60] (33.5s) | LR: 0.000655 | Train: 68.61% | Val: 76.30%\n",
      "Epoch [ 15/60] (33.5s) | LR: 0.000501 | Train: 71.49% | Val: 80.50%\n",
      "Epoch [ 16/60] (33.5s) | LR: 0.000346 | Train: 75.30% | Val: 81.35%\n",
      "Epoch [ 17/60] (33.4s) | LR: 0.000207 | Train: 79.89% | Val: 84.85% ✨ BEST!\n",
      "Epoch [ 18/60] (33.3s) | LR: 0.000096 | Train: 80.68% | Val: 84.43%\n",
      "Epoch [ 19/60] (33.3s) | LR: 0.000025 | Train: 83.69% | Val: 87.52% ✨ BEST!\n",
      "Epoch [ 20/60] (33.4s) | LR: 0.001000 | Train: 83.67% | Val: 87.52%\n",
      "Epoch [ 21/60] (33.5s) | LR: 0.000976 | Train: 73.01% | Val: 77.70%\n",
      "Epoch [ 22/60] (33.5s) | LR: 0.000905 | Train: 74.04% | Val: 77.98%\n",
      "Epoch [ 23/60] (33.5s) | LR: 0.000794 | Train: 74.92% | Val: 77.14%\n",
      "Epoch [ 24/60] (33.5s) | LR: 0.000655 | Train: 76.97% | Val: 78.26%\n",
      "Epoch [ 25/60] (33.5s) | LR: 0.000501 | Train: 79.03% | Val: 81.21%\n",
      "Epoch [ 26/60] (33.4s) | LR: 0.000346 | Train: 82.23% | Val: 82.75%\n",
      "Epoch [ 27/60] (33.3s) | LR: 0.000207 | Train: 83.06% | Val: 86.82%\n",
      "Epoch [ 28/60] (33.3s) | LR: 0.000096 | Train: 85.36% | Val: 86.96%\n",
      "Epoch [ 29/60] (33.3s) | LR: 0.000025 | Train: 87.62% | Val: 88.92% ✨ BEST!\n",
      "Epoch [ 30/60] (33.3s) | LR: 0.001000 | Train: 87.93% | Val: 89.76% ✨ BEST!\n",
      "Epoch [ 31/60] (33.4s) | LR: 0.000976 | Train: 77.70% | Val: 81.49%\n",
      "Epoch [ 32/60] (33.3s) | LR: 0.000905 | Train: 77.85% | Val: 73.63%\n",
      "Epoch [ 33/60] (33.3s) | LR: 0.000794 | Train: 79.18% | Val: 79.24%\n",
      "Epoch [ 34/60] (33.4s) | LR: 0.000655 | Train: 79.23% | Val: 81.63%\n",
      "Epoch [ 35/60] (33.4s) | LR: 0.000501 | Train: 84.16% | Val: 85.27%\n",
      "Epoch [ 36/60] (33.5s) | LR: 0.000346 | Train: 85.76% | Val: 87.38%\n",
      "Epoch [ 37/60] (33.6s) | LR: 0.000207 | Train: 86.88% | Val: 87.52%\n",
      "Epoch [ 38/60] (33.5s) | LR: 0.000096 | Train: 87.33% | Val: 90.74% ✨ BEST!\n",
      "Epoch [ 39/60] (33.3s) | LR: 0.000025 | Train: 89.42% | Val: 90.04%\n",
      "Epoch [ 40/60] (33.3s) | LR: 0.001000 | Train: 86.41% | Val: 90.04%\n",
      "Epoch [ 41/60] (33.3s) | LR: 0.000976 | Train: 80.97% | Val: 83.73%\n",
      "Epoch [ 42/60] (33.4s) | LR: 0.000905 | Train: 81.73% | Val: 82.89%\n",
      "Epoch [ 43/60] (33.5s) | LR: 0.000794 | Train: 81.15% | Val: 83.59%\n",
      "Epoch [ 44/60] (33.4s) | LR: 0.000655 | Train: 82.22% | Val: 81.91%\n",
      "Epoch [ 45/60] (33.4s) | LR: 0.000501 | Train: 83.89% | Val: 89.48%\n",
      "Epoch [ 46/60] (33.6s) | LR: 0.000346 | Train: 88.79% | Val: 87.24%\n",
      "Epoch [ 47/60] (33.5s) | LR: 0.000207 | Train: 88.85% | Val: 87.94%\n",
      "Epoch [ 48/60] (33.4s) | LR: 0.000096 | Train: 90.07% | Val: 88.64%\n",
      "Epoch [ 49/60] (33.3s) | LR: 0.000025 | Train: 90.69% | Val: 90.60%\n",
      "Epoch [ 50/60] (33.3s) | LR: 0.001000 | Train: 91.99% | Val: 90.46%\n",
      "Epoch [ 51/60] (33.3s) | LR: 0.000976 | Train: 83.48% | Val: 80.93%\n",
      "Epoch [ 52/60] (33.3s) | LR: 0.000905 | Train: 82.52% | Val: 84.57%\n",
      "Epoch [ 53/60] (33.3s) | LR: 0.000794 | Train: 85.19% | Val: 81.35%\n",
      "Epoch [ 54/60] (33.4s) | LR: 0.000655 | Train: 85.69% | Val: 85.27%\n",
      "Epoch [ 55/60] (33.5s) | LR: 0.000501 | Train: 89.59% | Val: 84.85%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 185\u001b[39m\n\u001b[32m    182\u001b[39m epoch_start = time.time()\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Train with mixup\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m    188\u001b[39m val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer, device, use_mixup)\u001b[39m\n\u001b[32m     70\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m     71\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * images.size(\u001b[32m0\u001b[39m)\n\u001b[32m     74\u001b[39m _, predicted = torch.max(outputs.data, \u001b[32m1\u001b[39m)\n\u001b[32m     75\u001b[39m total += labels.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "MIXUP_ALPHA = 0.2\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "print(f\"✅ Optimizer: AdamW (lr={LEARNING_RATE}, weight_decay=1e-4)\")\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,\n",
    "    T_mult=1,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "print(f\"✅ Scheduler: CosineAnnealingWarmRestarts (T_0=10)\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "print(f\"✅ Loss: CrossEntropyLoss + Label Smoothing + Class Weights\")\n",
    "print(f\"✅ Mixup: Enabled (alpha={MIXUP_ALPHA})\")\n",
    "print(f\"✅ Epochs: {NUM_EPOCHS}\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=12, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model = None\n",
    "    \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        self.best_model = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "early_stopping = EarlyStopping(patience=12)\n",
    "print(f\"✅ Early Stopping: patience=12\")\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, use_mixup=True):\n",
    "    \"\"\"Training with MIXUP\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Apply mixup\n",
    "        if use_mixup and np.random.rand() > 0.5:\n",
    "            images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=MIXUP_ALPHA)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (lam * (predicted == labels_a).sum().item() + \n",
    "                       (1 - lam) * (predicted == labels_b).sum().item())\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Standard validation\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate_with_tta(model, dataloader, criterion, device, num_tta=5):\n",
    "    \"\"\"Validation with Test-Time Augmentation\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    tta_transforms = [\n",
    "        transforms.RandomHorizontalFlip(p=1.0),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomRotation(-10),\n",
    "        transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=1.0),\n",
    "            transforms.RandomRotation(5)\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            all_outputs = []\n",
    "            all_outputs.append(model(images))\n",
    "            \n",
    "            # Apply different augmentations\n",
    "            for i in range(min(num_tta - 1, len(tta_transforms))):\n",
    "                aug_images = images.clone()\n",
    "                for j in range(images.size(0)):\n",
    "                    # Convert to PIL, apply transform, convert back\n",
    "                    img_pil = transforms.ToPILImage()(images[j].cpu())\n",
    "                    img_aug = tta_transforms[i](img_pil)\n",
    "                    aug_images[j] = transforms.ToTensor()(img_aug)\n",
    "                aug_images = aug_images.to(device)\n",
    "                all_outputs.append(model(aug_images))\n",
    "            \n",
    "            outputs = torch.stack(all_outputs).mean(0)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STARTING TRAINING - IMPROVED RESNET50\")\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_epoch = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train with mixup\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print progress\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"Epoch [{epoch+1:3d}/{NUM_EPOCHS}] ({epoch_time:4.1f}s) | \"\n",
    "          f\"LR: {current_lr:.6f} | \"\n",
    "          f\"Train: {train_acc:5.2f}% | \"\n",
    "          f\"Val: {val_acc:5.2f}%\", end='')\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'history': history\n",
    "        }, 'best_resnet50_improved.pth')\n",
    "        print(\" ✨ BEST!\", end='')\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Milestone messages\n",
    "    if epoch > 0:\n",
    "        if val_acc >= 93 and history['val_acc'][-2] < 93:\n",
    "            print(\"   🎯 Milestone: 93% accuracy - Excellent!\")\n",
    "        elif val_acc >= 95 and history['val_acc'][-2] < 95:\n",
    "            print(\"   🏆 OUTSTANDING: 95% accuracy achieved!\")\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"\\nℹ️  Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✅ TRAINING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"⏱️  Total training time: {total_time/60:.1f} minutes\")\n",
    "print(f\"🏆 Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"📍 Best epoch: {best_epoch}\")\n",
    "print(f\"💾 Model saved as: best_resnet50_improved.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e70252d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c23b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL EVALUATION WITH TEST-TIME AUGMENTATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('best_resnet50_improved.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Standard test\n",
    "test_loss, test_acc = validate_epoch(model, test_loader, criterion, device)\n",
    "print(f\"📊 Standard Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# Test with TTA\n",
    "print(\"🔄 Running Test-Time Augmentation...\")\n",
    "tta_loss, tta_acc = validate_with_tta(model, test_loader, criterion, device, num_tta=5)\n",
    "print(f\"🎯 TTA Test Accuracy: {tta_acc:.2f}% (boost: +{tta_acc-test_acc:.2f}%)\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# PLOT TRAINING HISTORY\n",
    "# ================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GENERATING TRAINING PLOTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0, 0].plot(history['train_acc'], label='Train Accuracy', linewidth=2)\n",
    "axes[0, 0].plot(history['val_acc'], label='Val Accuracy', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy (%)')\n",
    "axes[0, 0].set_title('Training and Validation Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 1].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 1].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].set_title('Training and Validation Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate plot\n",
    "axes[1, 0].plot(history['lr'], linewidth=2, color='green')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate Schedule')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "# Summary text\n",
    "summary_text = f\"\"\"\n",
    "TRAINING SUMMARY\n",
    "{'='*30}\n",
    "\n",
    "Best Val Accuracy: {best_val_acc:.2f}%\n",
    "Best Epoch: {best_epoch}\n",
    "Total Epochs: {len(history['train_acc'])}\n",
    "Training Time: {total_time/60:.1f} min\n",
    "\n",
    "Test Accuracy: {test_acc:.2f}%\n",
    "TTA Test Accuracy: {tta_acc:.2f}%\n",
    "TTA Improvement: +{tta_acc-test_acc:.2f}%\n",
    "\n",
    "Improvements Applied:\n",
    "✓ Mixup augmentation\n",
    "✓ Enhanced data augmentation\n",
    "✓ 40 epochs (optimized)\n",
    "✓ Test-Time Augmentation\n",
    "\"\"\"\n",
    "axes[1, 1].text(0.1, 0.5, summary_text, fontsize=11, family='monospace',\n",
    "                verticalalignment='center', bbox=dict(boxstyle='round', \n",
    "                facecolor='wheat', alpha=0.5))\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✅ Training plots saved as 'training_history.png'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✅ ALL DONE!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
